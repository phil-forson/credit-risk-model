{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4046d106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanned 1,000,000 | kept 201,694\n",
      "Scanned 2,000,000 | kept 402,800\n",
      "Scanned 3,000,000 | kept 601,918\n",
      "Scanned 4,000,000 | kept 802,521\n",
      "Scanned 5,000,000 | kept 1,001,355\n",
      "\n",
      "Done.\n",
      "Scanned 5,531,451 | kept 1,107,221 -> C:\\Users\\hp\\Desktop\\UTDALLAS\\Fall 25\\BUANML\\GroupProject\\outputs\\dev_sample_raw.csv.gz\n"
     ]
    }
   ],
   "source": [
    "# Constant-memory filter -> COMPRESSED CSV (GZIP)\n",
    "# Input: outputs/labels_20pct.parquet  +  train_data.csv  (same folder as notebook)\n",
    "# Output: outputs/dev_sample_raw.csv.gz\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import csv, gzip, os\n",
    "\n",
    "TRAIN_CSV = Path(\"train_data.csv\")\n",
    "OUT_DIR   = Path(\"outputs\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_GZ    = OUT_DIR / \"dev_sample_raw.csv.gz\"   # compressed!\n",
    "\n",
    "# Load sampled IDs (small)\n",
    "LABELS_20 = OUT_DIR / \"labels_20pct.parquet\"\n",
    "labels_20 = pd.read_parquet(LABELS_20)\n",
    "sample_ids = set(labels_20[\"customer_ID\"].astype(str))\n",
    "\n",
    "# Remove any old big files to free space\n",
    "for p in [OUT_DIR / \"dev_sample_raw.csv\", OUT_GZ]:\n",
    "    if p.exists():\n",
    "        try: p.unlink()\n",
    "        except Exception: pass\n",
    "\n",
    "scanned = kept = 0\n",
    "\n",
    "with open(TRAIN_CSV, \"r\", newline=\"\", encoding=\"utf-8\") as src, \\\n",
    "     gzip.open(OUT_GZ, \"wt\", newline=\"\", encoding=\"utf-8\") as dst:\n",
    "    r = csv.reader(src)\n",
    "    w = csv.writer(dst)\n",
    "\n",
    "    header = [h.strip() for h in next(r)]\n",
    "    try:\n",
    "        cid_idx = header.index(\"customer_ID\")\n",
    "    except ValueError:\n",
    "        raise RuntimeError(\"'customer_ID' not found in header.\")\n",
    "    w.writerow(header)\n",
    "\n",
    "    for row in r:\n",
    "        scanned += 1\n",
    "        if row[cid_idx] in sample_ids:\n",
    "            w.writerow(row)\n",
    "            kept += 1\n",
    "        if scanned % 1_000_000 == 0:\n",
    "            print(f\"Scanned {scanned:,} | kept {kept:,}\")\n",
    "\n",
    "print(\"\\nDone.\")\n",
    "print(f\"Scanned {scanned:,} | kept {kept:,} -> {OUT_GZ.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1f89872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customers in labels_20: 91783\n",
      "customers found in dev : 91783\n",
      "coverage: 1.0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "OUT = Path(\"outputs\")\n",
    "dev_gz = OUT / \"dev_sample_raw.csv.gz\"\n",
    "lbl_pq = OUT / \"labels_20pct.parquet\"\n",
    "\n",
    "assert dev_gz.exists(), \"dev_sample_raw.csv.gz not found\"\n",
    "labels_20 = pd.read_parquet(lbl_pq)\n",
    "want = set(labels_20[\"customer_ID\"].astype(str))\n",
    "\n",
    "# check coverage using a light read of only customer_ID\n",
    "seen = set()\n",
    "for chunk in pd.read_csv(dev_gz, usecols=[\"customer_ID\"], dtype={\"customer_ID\":\"string\"}, chunksize=200_000):\n",
    "    seen.update(chunk[\"customer_ID\"])\n",
    "\n",
    "print(\"customers in labels_20:\", len(want))\n",
    "print(\"customers found in dev :\", len(seen))\n",
    "print(\"coverage:\", len(seen & want) / len(want))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f73f95c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in dataset: 190\n",
      "\n",
      "Column types:\n",
      "float64    185\n",
      "object       4\n",
      "int64        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First few column names:\n",
      "['customer_ID', 'S_2', 'P_2', 'D_39', 'B_1', 'B_2', 'R_1', 'S_3', 'D_41', 'B_3', 'D_42', 'D_43', 'D_44', 'B_4', 'D_45', 'B_5', 'R_2', 'D_46', 'D_47', 'D_48']\n"
     ]
    }
   ],
   "source": [
    "# Step 5: One-Hot Encoding\n",
    "# First, let's examine the data structure to identify categorical variables\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "OUT = Path(\"outputs\")\n",
    "dev_gz = OUT / \"dev_sample_raw.csv.gz\"\n",
    "\n",
    "# Read a small sample to inspect columns\n",
    "sample = pd.read_csv(dev_gz, nrows=1000)\n",
    "print(\"Columns in dataset:\", len(sample.columns))\n",
    "print(\"\\nColumn types:\")\n",
    "print(sample.dtypes.value_counts())\n",
    "print(\"\\nFirst few column names:\")\n",
    "print(list(sample.columns[:20]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90bebd0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Better categorical probe (EDA only)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m categorical_cols \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m sample\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m      3\u001b[0m                     \u001b[38;5;28;01mif\u001b[39;00m sample[c]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD_63\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD_64\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCategoricals found:\u001b[39m\u001b[38;5;124m\"\u001b[39m, categorical_cols)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": [
    "# Better categorical probe (EDA only)\n",
    "categorical_cols = [c for c in sample.columns\n",
    "                    if sample[c].dtype == 'object' and c in ('D_63','D_64')]\n",
    "print(\"Categoricals found:\", categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aca57430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_25176\\2202462583.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  r = dev.groupby(\"customer_ID\", sort=False).apply(lambda g: last_k_mean(g, num_cols, k))\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_25176\\2202462583.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  r = dev.groupby(\"customer_ID\", sort=False).apply(lambda g: last_k_mean(g, num_cols, k))\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_25176\\2202462583.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  r = dev.groupby(\"customer_ID\", sort=False).apply(lambda g: last_k_mean(g, num_cols, k))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: outputs\\dev_sample_agg.csv.gz | shape: (91783, 762) | cats encoded: ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n"
     ]
    }
   ],
   "source": [
    "# Aggregation with full Kaggle categorical list (encode on last snapshot only)\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "OUT = Path(\"outputs\")\n",
    "DEV_GZ      = OUT / \"dev_sample_raw.csv.gz\"\n",
    "LABELS_20PQ = OUT / \"labels_20pct.parquet\"\n",
    "OUT_AGG_GZ  = OUT / \"dev_sample_agg.csv.gz\"\n",
    "\n",
    "# 1) Load\n",
    "dev = pd.read_csv(\n",
    "    DEV_GZ,\n",
    "    dtype={\"customer_ID\":\"string\"},\n",
    "    parse_dates=[\"S_2\"],\n",
    "    low_memory=True\n",
    ")\n",
    "labels_20 = pd.read_parquet(LABELS_20PQ)\n",
    "labels_20[\"customer_ID\"] = labels_20[\"customer_ID\"].astype(\"string\")\n",
    "tgt = \"target\" if \"target\" in labels_20.columns else labels_20.columns[-1]\n",
    "labels_20[tgt] = labels_20[tgt].astype(int)\n",
    "\n",
    "# 2) Known categoricals from Kaggle (keep only those present)\n",
    "KAGGLE_CATS = ['B_30','B_38','D_114','D_116','D_117','D_120','D_126','D_63','D_64','D_66','D_68']\n",
    "cat_cols = [c for c in KAGGLE_CATS if c in dev.columns]\n",
    "\n",
    "# 3) Sort for last-k logic and get the last row per customer\n",
    "dev = dev.sort_values([\"customer_ID\",\"S_2\"])\n",
    "last = dev.groupby(\"customer_ID\", sort=False).tail(1).copy()\n",
    "\n",
    "# 4) One-hot encode categoricals on the last snapshot only\n",
    "if cat_cols:\n",
    "    for c in cat_cols:\n",
    "        last[c] = last[c].astype(\"category\")\n",
    "    cats_last = pd.get_dummies(last[[\"customer_ID\"] + cat_cols],\n",
    "                               columns=cat_cols, dummy_na=True, dtype=\"uint8\")\n",
    "else:\n",
    "    cats_last = last[[\"customer_ID\"]].copy()\n",
    "\n",
    "# 5) Numeric columns to aggregate (exclude ID, date, and raw cats)\n",
    "ignore = {\"customer_ID\",\"S_2\"} | set(cat_cols)\n",
    "num_cols = [c for c in dev.columns if c not in ignore and np.issubdtype(dev[c].dtype, np.number)]\n",
    "if not num_cols:\n",
    "    raise RuntimeError(\"No numeric features to aggregate.\")\n",
    "\n",
    "# 6) Last values for numeric\n",
    "last_vals = last[[\"customer_ID\"] + num_cols].copy().set_index(\"customer_ID\")\n",
    "last_vals.columns = [f\"{c}_last\" for c in last_vals.columns]\n",
    "\n",
    "# 7) Rolling means over last 3/6/12 rows for numeric only\n",
    "def last_k_mean(g, cols, k): return g[cols].tail(k).mean()\n",
    "\n",
    "rolled = []\n",
    "for k in [3,6,12]:\n",
    "    r = dev.groupby(\"customer_ID\", sort=False).apply(lambda g: last_k_mean(g, num_cols, k))\n",
    "    r.index.name = \"customer_ID\"\n",
    "    r.columns = [f\"{c}_mean{k}\" for c in r.columns]\n",
    "    for c in r.columns: r[c] = r[c].astype(np.float32)\n",
    "    rolled.append(r)\n",
    "\n",
    "# 8) Combine numeric aggs + last-snapshot categoricals, join target\n",
    "agg = pd.concat([last_vals] + rolled, axis=1).reset_index()\n",
    "agg = agg.merge(cats_last, on=\"customer_ID\", how=\"left\").merge(\n",
    "    labels_20[[\"customer_ID\", tgt]], on=\"customer_ID\", how=\"inner\"\n",
    ")\n",
    "\n",
    "# 9) Save\n",
    "agg.to_csv(OUT_AGG_GZ, index=False, compression=\"gzip\")\n",
    "print(\"Saved:\", OUT_AGG_GZ, \"| shape:\", agg.shape, \"| cats encoded:\", cat_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d85089d",
   "metadata": {},
   "source": [
    "# Step 6: Feature Engineering\n",
    "\n",
    "Next steps for feature engineering:\n",
    "1. Load the encoded dataset and labels\n",
    "2. Merge labels with the data\n",
    "3. Aggregate historical data (up to 13 months) per customer to create features as of April 2018\n",
    "4. For numerical features: create aggregates (Average, Sum, Min, Max) over different time windows (3, 6, 9, 12 months)\n",
    "5. Include the most recent value (April 2018) for each feature\n",
    "6. Handle missing data (some customers may have less than 13 months of data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10ffdb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes -> Train: (64248, 792) Test1: (13767, 792) Test2: (13768, 792)\n",
      "AUC Train=0.9980  Test1=0.9531  Test2=0.9519\n",
      "Saved FI -> outputs\\xgb_fi_default.csv\n",
      "AUC Train=0.9960  Test1=0.9395  Test2=0.9349\n",
      "Saved FI -> outputs\\xgb_fi_tuned.csv\n",
      "Selected 14 features with FI ≥ 0.5%. Saved -> outputs/selected_features.txt\n"
     ]
    }
   ],
   "source": [
    "# Split 70/15/15 by customer, run two XGBs, save feature importances, select features (≥0.5%)\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "\n",
    "OUT = Path(\"outputs\")\n",
    "AGG = OUT / \"dev_sample_agg.csv.gz\"   # created in the aggregation step\n",
    "assert AGG.exists(), \"Run the aggregation step first to create outputs/dev_sample_agg.csv.gz\"\n",
    "\n",
    "# 1) Load aggregated, build X/y\n",
    "df = pd.read_csv(AGG, dtype={\"customer_ID\":\"string\"})\n",
    "target_col = \"target\" if \"target\" in df.columns else df.columns[-1]\n",
    "X = df.drop(columns=[\"customer_ID\", target_col], errors=\"ignore\")\n",
    "y = df[target_col].astype(int).values\n",
    "\n",
    "# 2) 70/15/15 split (stratified)\n",
    "X_tr, X_tmp, y_tr, y_tmp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "X_t1, X_t2, y_t1, y_t2 = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.50, random_state=42, stratify=y_tmp\n",
    ")\n",
    "\n",
    "print(\"Shapes ->\",\n",
    "      \"Train:\", X_tr.shape,\n",
    "      \"Test1:\", X_t1.shape,\n",
    "      \"Test2:\", X_t2.shape)\n",
    "\n",
    "# Utility to compute FI (gain-based) as % of total\n",
    "def xgb_fit_and_fi(model, Xtr, ytr, Xt1, yt1, Xt2, yt2, fi_path):\n",
    "    model.fit(Xtr, ytr)\n",
    "    # AUCs (quick check)\n",
    "    p_tr = model.predict_proba(Xtr)[:,1]\n",
    "    p_t1 = model.predict_proba(Xt1)[:,1]\n",
    "    p_t2 = model.predict_proba(Xt2)[:,1]\n",
    "    print(f\"AUC Train={roc_auc_score(ytr,p_tr):.4f}  \"\n",
    "          f\"Test1={roc_auc_score(yt1,p_t1):.4f}  \"\n",
    "          f\"Test2={roc_auc_score(yt2,p_t2):.4f}\")\n",
    "\n",
    "    booster = model.get_booster()\n",
    "    gain = booster.get_score(importance_type=\"gain\")\n",
    "    fi = pd.DataFrame({\"feature\": list(gain.keys()), \"gain\": list(gain.values())})\n",
    "    fi[\"pct\"] = fi[\"gain\"] / fi[\"gain\"].sum()\n",
    "    fi.sort_values(\"pct\", ascending=False).to_csv(fi_path, index=False)\n",
    "    print(\"Saved FI ->\", fi_path)\n",
    "    return fi\n",
    "\n",
    "# 3) XGB (default-ish)\n",
    "model_default = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    "    tree_method=\"hist\",\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "fi_default = xgb_fit_and_fi(model_default, X_tr, y_tr, X_t1, y_t1, X_t2, y_t2,\n",
    "                            OUT / \"xgb_fi_default.csv\")\n",
    "\n",
    "# 4) XGB (tuned as per spec in the brief)\n",
    "model_tuned = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    "    tree_method=\"hist\",\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.5,\n",
    "    max_depth=4,\n",
    "    subsample=0.5,\n",
    "    colsample_bytree=0.5,\n",
    "    scale_pos_weight=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "fi_tuned = xgb_fit_and_fi(model_tuned, X_tr, y_tr, X_t1, y_t1, X_t2, y_t2,\n",
    "                          OUT / \"xgb_fi_tuned.csv\")\n",
    "\n",
    "# 5) Keep features with FI ≥ 0.5% in either model\n",
    "keep = set(fi_default.loc[fi_default[\"pct\"] >= 0.005, \"feature\"]).union(\n",
    "       set(fi_tuned.loc[fi_tuned[\"pct\"] >= 0.005, \"feature\"])\n",
    ")\n",
    "keep = sorted(keep)\n",
    "\n",
    "# Save the selection for the grid-search step\n",
    "(OUT / \"selected_features.txt\").write_text(\"\\n\".join(keep), encoding=\"utf-8\")\n",
    "print(f\"Selected {len(keep)} features with FI ≥ 0.5%. Saved -> outputs/selected_features.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae85bf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved grid -> outputs\\xgb_grid_results.csv\n",
      "Best: {'#Trees': 100.0, 'LR': 0.1, 'Subsample': 0.8, '%Features': 0.5, 'Weight': 1.0, 'AUC_Train': 0.9597726204942625, 'AUC_Test1': 0.9461327880873672, 'AUC_Test2': 0.9452347912413078, 'AUC_Mean': 0.9503800666076457, 'AUC_Std': 0.008146572958528707, 'score': 0.9463067801283814}\n",
      "Saved best params -> outputs/xgb_best_params.json\n"
     ]
    }
   ],
   "source": [
    "# Grid search using selected features (from outputs/selected_features.txt)\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np, json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "\n",
    "OUT = Path(\"outputs\")\n",
    "AGG = OUT / \"dev_sample_agg.csv.gz\"\n",
    "SEL = OUT / \"selected_features.txt\"\n",
    "assert AGG.exists() and SEL.exists(), \"Need dev_sample_agg.csv.gz and selected_features.txt\"\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(AGG, dtype={\"customer_ID\":\"string\"})\n",
    "target_col = \"target\" if \"target\" in df.columns else df.columns[-1]\n",
    "\n",
    "with open(SEL, \"r\", encoding=\"utf-8\") as f:\n",
    "    keep = [ln.strip() for ln in f if ln.strip()]\n",
    "# keep only features that still exist (safety)\n",
    "keep = [c for c in keep if c in df.columns]\n",
    "\n",
    "X = df[keep].copy()\n",
    "y = df[target_col].astype(int).values\n",
    "cust = df[\"customer_ID\"].astype(\"string\").values\n",
    "\n",
    "# 70/15/15 splits (keep customer ids aligned)\n",
    "X_tr, X_tmp, y_tr, y_tmp, c_tr, c_tmp = train_test_split(\n",
    "    X, y, cust, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "X_t1, X_t2, y_t1, y_t2, c_t1, c_t2 = train_test_split(\n",
    "    X_tmp, y_tmp, c_tmp, test_size=0.50, random_state=42, stratify=y_tmp\n",
    ")\n",
    "\n",
    "grid = {\n",
    "    \"n_estimators\": [50, 100, 300],\n",
    "    \"learning_rate\": [0.01, 0.1],\n",
    "    \"subsample\": [0.5, 0.8],\n",
    "    \"colsample_bytree\": [0.5, 1.0],\n",
    "    \"scale_pos_weight\": [1, 5, 10],\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for n in grid[\"n_estimators\"]:\n",
    "    for lr in grid[\"learning_rate\"]:\n",
    "        for ss in grid[\"subsample\"]:\n",
    "            for cs in grid[\"colsample_bytree\"]:\n",
    "                for w in grid[\"scale_pos_weight\"]:\n",
    "                    model = xgb.XGBClassifier(\n",
    "                        objective=\"binary:logistic\",\n",
    "                        eval_metric=\"auc\",\n",
    "                        tree_method=\"hist\",\n",
    "                        n_estimators=n,\n",
    "                        learning_rate=lr,\n",
    "                        subsample=ss,\n",
    "                        colsample_bytree=cs,\n",
    "                        scale_pos_weight=w,\n",
    "                        random_state=42,\n",
    "                        n_jobs=-1,\n",
    "                    )\n",
    "                    model.fit(X_tr, y_tr)\n",
    "                    p_tr = model.predict_proba(X_tr)[:, 1]\n",
    "                    p_t1 = model.predict_proba(X_t1)[:, 1]\n",
    "                    p_t2 = model.predict_proba(X_t2)[:, 1]\n",
    "                    rows.append({\n",
    "                        \"#Trees\": n, \"LR\": lr, \"Subsample\": ss, \"%Features\": cs, \"Weight\": w,\n",
    "                        \"AUC_Train\": roc_auc_score(y_tr, p_tr),\n",
    "                        \"AUC_Test1\": roc_auc_score(y_t1, p_t1),\n",
    "                        \"AUC_Test2\": roc_auc_score(y_t2, p_t2),\n",
    "                    })\n",
    "\n",
    "grid_df = pd.DataFrame(rows)\n",
    "grid_df[\"AUC_Mean\"] = grid_df[[\"AUC_Train\", \"AUC_Test1\", \"AUC_Test2\"]].mean(axis=1)\n",
    "grid_df[\"AUC_Std\"]  = grid_df[[\"AUC_Train\", \"AUC_Test1\", \"AUC_Test2\"]].std(axis=1)\n",
    "grid_df[\"score\"]    = grid_df[\"AUC_Mean\"] - 0.5*grid_df[\"AUC_Std\"]\n",
    "\n",
    "grid_path = OUT / \"xgb_grid_results.csv\"\n",
    "grid_df.to_csv(grid_path, index=False)\n",
    "best = grid_df.sort_values(\"score\", ascending=False).iloc[0].to_dict()\n",
    "print(\"Saved grid ->\", grid_path)\n",
    "print(\"Best:\", best)\n",
    "\n",
    "best_params = {\n",
    "    \"n_estimators\": int(best[\"#Trees\"]),\n",
    "    \"learning_rate\": float(best[\"LR\"]),\n",
    "    \"subsample\": float(best[\"Subsample\"]),\n",
    "    \"colsample_bytree\": float(best[\"%Features\"]),\n",
    "    \"scale_pos_weight\": float(best[\"Weight\"]),\n",
    "}\n",
    "(OUT / \"xgb_best_params.json\").write_text(json.dumps(best_params, indent=2))\n",
    "print(\"Saved best params -> outputs/xgb_best_params.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "236b5a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC (fit set):    0.9578198757587091\n",
      "AUC (HOLDOUT):    0.9454892883442277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_25176\\1528062809.py:55: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  ro = df_.groupby(\"bin\")[\"y\"].mean()\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_25176\\1528062809.py:55: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  ro = df_.groupby(\"bin\")[\"y\"].mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot -> outputs/xgb_rank_order.png\n",
      "Saved model -> outputs/xgb_final.json\n",
      "Saved holdout scores -> outputs/xgb_scores_test2.csv\n"
     ]
    }
   ],
   "source": [
    "# Final fit + holdout evaluation + rank-ordering plot + save predictions\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np, json, matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "\n",
    "OUT = Path(\"outputs\")\n",
    "AGG = OUT / \"dev_sample_agg.csv.gz\"\n",
    "SEL = OUT / \"selected_features.txt\"\n",
    "BEST = OUT / \"xgb_best_params.json\"\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(AGG, dtype={\"customer_ID\":\"string\"})\n",
    "target_col = \"target\" if \"target\" in df.columns else df.columns[-1]\n",
    "with open(SEL, \"r\", encoding=\"utf-8\") as f:\n",
    "    keep = [ln.strip() for ln in f if ln.strip() and ln.strip() in df.columns]\n",
    "best_params = json.loads(BEST.read_text())\n",
    "\n",
    "X = df[keep].copy()\n",
    "y = df[target_col].astype(int).values\n",
    "cust = df[\"customer_ID\"].astype(\"string\").values\n",
    "\n",
    "# Splits (same as grid cell)\n",
    "X_tr, X_tmp, y_tr, y_tmp, c_tr, c_tmp = train_test_split(\n",
    "    X, y, cust, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "X_t1, X_t2, y_t1, y_t2, c_t1, c_t2 = train_test_split(\n",
    "    X_tmp, y_tmp, c_tmp, test_size=0.50, random_state=42, stratify=y_tmp\n",
    ")\n",
    "\n",
    "# Refit on Train+Test1, evaluate on Test2\n",
    "X_fit = pd.concat([X_tr, X_t1], axis=0)\n",
    "y_fit = np.concatenate([y_tr, y_t1])\n",
    "model = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    **best_params\n",
    ")\n",
    "model.fit(X_fit, y_fit)\n",
    "\n",
    "p_fit = model.predict_proba(X_fit)[:,1]\n",
    "p_hold = model.predict_proba(X_t2)[:,1]\n",
    "print(\"AUC (fit set):   \", roc_auc_score(y_fit, p_fit))\n",
    "print(\"AUC (HOLDOUT):   \", roc_auc_score(y_t2, p_hold))\n",
    "\n",
    "# Rank-ordering (deciles)\n",
    "def rank_order(y, scores, q=10):\n",
    "    df_ = pd.DataFrame({\"y\": y, \"s\": scores})\n",
    "    df_[\"bin\"] = pd.qcut(df_[\"s\"], q, duplicates=\"drop\")\n",
    "    ro = df_.groupby(\"bin\")[\"y\"].mean()\n",
    "    ro.index = range(len(ro))\n",
    "    return ro\n",
    "\n",
    "ro_fit  = rank_order(y_fit, p_fit)\n",
    "ro_hold = rank_order(y_t2, p_hold)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ro_fit.index, ro_fit.values, marker=\"o\", label=\"Fit (Train+Test1)\")\n",
    "plt.plot(ro_hold.index, ro_hold.values, marker=\"o\", label=\"Holdout (Test2)\")\n",
    "plt.xlabel(\"Score decile (low → high)\")\n",
    "plt.ylabel(\"Default rate\")\n",
    "plt.title(\"Rank Ordering — XGB (best params)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT / \"xgb_rank_order.png\", dpi=150)\n",
    "plt.close()\n",
    "print(\"Saved plot -> outputs/xgb_rank_order.png\")\n",
    "\n",
    "# Save model + holdout scores\n",
    "model.save_model(str(OUT / \"xgb_final.json\"))\n",
    "pd.DataFrame({\"customer_ID\": c_t2, \"y_true\": y_t2, \"score\": p_hold}).to_csv(\n",
    "    OUT / \"xgb_scores_test2.csv\", index=False\n",
    ")\n",
    "print(\"Saved model -> outputs/xgb_final.json\")\n",
    "print(\"Saved holdout scores -> outputs/xgb_scores_test2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b19421b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved -> outputs/nn_grid_results.csv\n",
      "Best (by mean-0.5*std): {'params': {'layers': (128, 64), 'lr': 0.001, 'alpha': 0.0001, 'batch': 512}, 'auc_train': np.float64(0.9465945782649551), 'auc_t1': np.float64(0.944309602412749), 'auc_t2': np.float64(0.9431662909143544)}\n",
      "Final NN AUC (fit): 0.9462795521742915\n",
      "Final NN AUC (holdout): 0.9434037152398183\n",
      "Saved -> nn_final.joblib, nn_scores_test2.csv, nn_best_params.json\n"
     ]
    }
   ],
   "source": [
    "# ---- Point 11: Neural Network grid search (sklearn MLP) ----\n",
    "# Inputs: outputs/dev_sample_agg.csv.gz  +  outputs/selected_features.txt (from XGB FI step)\n",
    "# Outputs: outputs/nn_grid_results.csv, outputs/nn_best_params.json,\n",
    "#          outputs/nn_final.joblib, outputs/nn_scores_test2.csv\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np, json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import joblib\n",
    "\n",
    "OUT = Path(\"outputs\")\n",
    "AGG = OUT / \"dev_sample_agg.csv.gz\"\n",
    "SEL = OUT / \"selected_features.txt\"\n",
    "assert AGG.exists() and SEL.exists(), \"Run aggregation + feature selection first.\"\n",
    "\n",
    "# ---- Load features/labels (use the same selected features as XGB for fairness) ----\n",
    "df = pd.read_csv(AGG, dtype={\"customer_ID\":\"string\"})\n",
    "target = \"target\" if \"target\" in df.columns else df.columns[-1]\n",
    "with open(SEL, \"r\", encoding=\"utf-8\") as f:\n",
    "    keep = [ln.strip() for ln in f if ln.strip() and ln.strip() in df.columns]\n",
    "\n",
    "X = df[keep].copy()\n",
    "y = df[target].astype(int).values\n",
    "cust = df[\"customer_ID\"].astype(\"string\").values\n",
    "\n",
    "# ---- 70/15/15 split (same seed as before) ----\n",
    "X_tr, X_tmp, y_tr, y_tmp, c_tr, c_tmp = train_test_split(\n",
    "    X, y, cust, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "X_t1, X_t2, y_t1, y_t2, c_t1, c_t2 = train_test_split(\n",
    "    X_tmp, y_tmp, c_tmp, test_size=0.50, random_state=42, stratify=y_tmp\n",
    ")\n",
    "\n",
    "# ---- Preprocess: cap/floor by train quantiles, then impute + standardize ----\n",
    "q_lo = X_tr.quantile(0.01); q_hi = X_tr.quantile(0.99)\n",
    "def clip(df_): return df_.clip(q_lo, q_hi, axis=1)\n",
    "\n",
    "X_tr_c = clip(X_tr); X_t1_c = clip(X_t1); X_t2_c = clip(X_t2)\n",
    "\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "X_tr_i = imp.fit_transform(X_tr_c)\n",
    "X_t1_i = imp.transform(X_t1_c)\n",
    "X_t2_i = imp.transform(X_t2_c)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_tr_s = sc.fit_transform(X_tr_i)\n",
    "X_t1_s = sc.transform(X_t1_i)\n",
    "X_t2_s = sc.transform(X_t2_i)\n",
    "\n",
    "# ---- Grid (keep small to be fast; expand later if you like) ----\n",
    "grid = [\n",
    "    {\"layers\": (128,),        \"lr\": 1e-3, \"alpha\": 1e-4, \"batch\": 512},\n",
    "    {\"layers\": (256,),        \"lr\": 1e-3, \"alpha\": 1e-4, \"batch\": 512},\n",
    "    {\"layers\": (128, 64),     \"lr\": 1e-3, \"alpha\": 1e-4, \"batch\": 512},\n",
    "    {\"layers\": (256, 128),    \"lr\": 1e-3, \"alpha\": 1e-4, \"batch\": 512},\n",
    "    {\"layers\": (128,),        \"lr\": 1e-4, \"alpha\": 1e-4, \"batch\": 1024},\n",
    "    {\"layers\": (128, 64),     \"lr\": 1e-4, \"alpha\": 1e-3, \"batch\": 1024},\n",
    "]\n",
    "\n",
    "rows = []\n",
    "best = None\n",
    "best_score = -1e9\n",
    "for g in grid:\n",
    "    clf = MLPClassifier(\n",
    "        hidden_layer_sizes=g[\"layers\"],\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        learning_rate_init=g[\"lr\"],\n",
    "        alpha=g[\"alpha\"],\n",
    "        batch_size=g[\"batch\"],\n",
    "        max_iter=50,                 # keep short; we use early stopping\n",
    "        early_stopping=True,\n",
    "        n_iter_no_change=5,\n",
    "        validation_fraction=0.1,\n",
    "        random_state=42,\n",
    "        verbose=False,\n",
    "    )\n",
    "    clf.fit(X_tr_s, y_tr)\n",
    "\n",
    "    p_tr = clf.predict_proba(X_tr_s)[:,1]\n",
    "    p_t1 = clf.predict_proba(X_t1_s)[:,1]\n",
    "    p_t2 = clf.predict_proba(X_t2_s)[:,1]\n",
    "\n",
    "    auc_tr  = roc_auc_score(y_tr,  p_tr)\n",
    "    auc_t1  = roc_auc_score(y_t1,  p_t1)\n",
    "    auc_t2  = roc_auc_score(y_t2,  p_t2)\n",
    "    auc_mu  = np.mean([auc_tr, auc_t1, auc_t2])\n",
    "    auc_std = np.std([auc_tr, auc_t1, auc_t2])\n",
    "    score   = auc_mu - 0.5*auc_std     # prefer high mean, low variance\n",
    "\n",
    "    rows.append({\n",
    "        \"Layers\": g[\"layers\"], \"LR\": g[\"lr\"], \"Alpha\": g[\"alpha\"], \"Batch\": g[\"batch\"],\n",
    "        \"AUC_Train\": auc_tr, \"AUC_Test1\": auc_t1, \"AUC_Test2\": auc_t2,\n",
    "        \"AUC_Mean\": auc_mu, \"AUC_Std\": auc_std, \"score\": score\n",
    "    })\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best = {\"params\": g, \"auc_train\": auc_tr, \"auc_t1\": auc_t1, \"auc_t2\": auc_t2}\n",
    "\n",
    "grid_df = pd.DataFrame(rows)\n",
    "grid_df.to_csv(OUT / \"nn_grid_results.csv\", index=False)\n",
    "print(\"Saved -> outputs/nn_grid_results.csv\")\n",
    "print(\"Best (by mean-0.5*std):\", best)\n",
    "\n",
    "# ---- Refit best NN on Train+Test1, evaluate on holdout (Test2), save artifacts ----\n",
    "X_fit = np.vstack([X_tr_s, X_t1_s])\n",
    "y_fit = np.concatenate([y_tr, y_t1])\n",
    "best_g = best[\"params\"]\n",
    "final = MLPClassifier(\n",
    "    hidden_layer_sizes=best_g[\"layers\"], activation=\"relu\", solver=\"adam\",\n",
    "    learning_rate_init=best_g[\"lr\"], alpha=best_g[\"alpha\"], batch_size=best_g[\"batch\"],\n",
    "    max_iter=100, early_stopping=True, n_iter_no_change=8, validation_fraction=0.1,\n",
    "    random_state=42, verbose=False\n",
    ").fit(X_fit, y_fit)\n",
    "\n",
    "p_fit  = final.predict_proba(X_fit)[:,1]\n",
    "p_hold = final.predict_proba(X_t2_s)[:,1]\n",
    "print(\"Final NN AUC (fit):\", roc_auc_score(y_fit, p_fit))\n",
    "print(\"Final NN AUC (holdout):\", roc_auc_score(y_t2, p_hold))\n",
    "\n",
    "# Save pipeline pieces + model\n",
    "artifacts = {\n",
    "    \"q_lo\": q_lo.to_dict(), \"q_hi\": q_hi.to_dict(),\n",
    "    \"imputer\": imp, \"scaler\": sc, \"model\": final, \"features\": keep\n",
    "}\n",
    "joblib.dump(artifacts, OUT / \"nn_final.joblib\")\n",
    "pd.DataFrame({\"customer_ID\": c_t2, \"y_true\": y_t2, \"score\": p_hold}).to_csv(\n",
    "    OUT / \"nn_scores_test2.csv\", index=False\n",
    ")\n",
    "(OUT / \"nn_best_params.json\").write_text(json.dumps(best_g, indent=2))\n",
    "print(\"Saved -> nn_final.joblib, nn_scores_test2.csv, nn_best_params.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d3bee08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\hp\\anaconda3\\anaconda3-new\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "Saved -> outputs/nn_grid_results.csv\n",
      "Best: {'grid': {'layers': 2, 'nodes': 6, 'activation': 'tanh', 'keep': 1.0, 'batch': 100}, 'metrics': {'AUC_Train': np.float64(0.9441669271055484), 'AUC_Test1': np.float64(0.9440770626885304), 'AUC_Test2': np.float64(0.9428032125963555)}}\n",
      "Final NN AUC (fit):    0.9436333004616435\n",
      "Final NN AUC (holdout): 0.9421228995294538\n",
      "Saved -> outputs/nn_final.keras, outputs/nn_scores_test2.csv, outputs/nn_best_params.json\n"
     ]
    }
   ],
   "source": [
    "# Point 12 — Neural Network preprocessing + grid, per brief\n",
    "\n",
    "from pathlib import Path\n",
    "import json, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "OUT = Path(\"outputs\")\n",
    "AGG = OUT / \"dev_sample_agg.csv.gz\"\n",
    "SEL = OUT / \"selected_features.txt\"\n",
    "assert AGG.exists() and SEL.exists(), \"Run steps up to feature selection first.\"\n",
    "\n",
    "# ---------- Load data & selected features ----------\n",
    "df = pd.read_csv(AGG, dtype={\"customer_ID\":\"string\"})\n",
    "target = \"target\" if \"target\" in df.columns else df.columns[-1]\n",
    "with open(SEL, \"r\", encoding=\"utf-8\") as f:\n",
    "    keep = [ln.strip() for ln in f if ln.strip() and ln.strip() in df.columns]\n",
    "\n",
    "X = df[keep].copy()\n",
    "y = df[target].astype(int).values\n",
    "cust = df[\"customer_ID\"].astype(\"string\").values\n",
    "\n",
    "# ---------- 70/15/15 split (same seed as other steps) ----------\n",
    "X_tr, X_tmp, y_tr, y_tmp, c_tr, c_tmp = train_test_split(\n",
    "    X, y, cust, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "X_t1, X_t2, y_t1, y_t2, c_t1, c_t2 = train_test_split(\n",
    "    X_tmp, y_tmp, c_tmp, test_size=0.50, random_state=42, stratify=y_tmp\n",
    ")\n",
    "\n",
    "# ---------- Preprocess (cap/floor at 1%/99%, missing=0, StandardScaler) ----------\n",
    "q_lo = X_tr.quantile(0.01); q_hi = X_tr.quantile(0.99)\n",
    "def clip(df_): return df_.clip(q_lo, q_hi, axis=1)\n",
    "\n",
    "X_tr_c = clip(X_tr).fillna(0.0)\n",
    "X_t1_c = clip(X_t1).fillna(0.0)\n",
    "X_t2_c = clip(X_t2).fillna(0.0)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_tr_s = sc.fit_transform(X_tr_c)\n",
    "X_t1_s = sc.transform(X_t1_c)\n",
    "X_t2_s = sc.transform(X_t2_c)\n",
    "\n",
    "n_features = X_tr_s.shape[1]\n",
    "\n",
    "# ---------- Model factory (supports dropout%, layers, nodes, activation) ----------\n",
    "def make_model(n_layers, n_nodes, activation, dropout_keep):\n",
    "    inputs = keras.Input(shape=(n_features,))\n",
    "    x = inputs\n",
    "    # dropout_keep == 1.0 means \"no dropout\", 0.5 means \"50% dropout\"\n",
    "    drop_rate = 1.0 - dropout_keep\n",
    "    for _ in range(n_layers):\n",
    "        x = keras.layers.Dense(n_nodes, activation=activation)(x)\n",
    "        if drop_rate > 0:\n",
    "            x = keras.layers.Dropout(drop_rate)(x)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    m = keras.Model(inputs, outputs)\n",
    "    m.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[keras.metrics.AUC(name=\"auc\")])\n",
    "    return m\n",
    "\n",
    "# ---------- Grid per brief ----------\n",
    "grid = []\n",
    "for n_layers in [2, 4]:\n",
    "    for n_nodes in [4, 6]:\n",
    "        for act in [\"relu\", \"tanh\"]:\n",
    "            for keep_prob in [0.5, 1.0]:          # 50% dropout, or none\n",
    "                for batch in [100, 10000]:\n",
    "                    grid.append({\n",
    "                        \"layers\": n_layers,\n",
    "                        \"nodes\": n_nodes,\n",
    "                        \"activation\": act,\n",
    "                        \"keep\": keep_prob,\n",
    "                        \"batch\": batch,\n",
    "                    })\n",
    "\n",
    "rows = []\n",
    "best = None; best_score = -1e9\n",
    "\n",
    "for g in grid:\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = make_model(g[\"layers\"], g[\"nodes\"], g[\"activation\"], g[\"keep\"])\n",
    "    # 20 epochs, as specified\n",
    "    hist = model.fit(\n",
    "        X_tr_s, y_tr,\n",
    "        epochs=20, batch_size=g[\"batch\"],\n",
    "        verbose=0, validation_data=(X_t1_s, y_t1)\n",
    "    )\n",
    "\n",
    "    p_tr = model.predict(X_tr_s, verbose=0).ravel()\n",
    "    p_t1 = model.predict(X_t1_s, verbose=0).ravel()\n",
    "    p_t2 = model.predict(X_t2_s, verbose=0).ravel()\n",
    "\n",
    "    auc_tr = roc_auc_score(y_tr, p_tr)\n",
    "    auc_t1 = roc_auc_score(y_t1, p_t1)\n",
    "    auc_t2 = roc_auc_score(y_t2, p_t2)\n",
    "    auc_mu = np.mean([auc_tr, auc_t1, auc_t2])\n",
    "    auc_sd = np.std([auc_tr, auc_t1, auc_t2])\n",
    "    score  = auc_mu - 0.5*auc_sd  # high mean, low variance\n",
    "\n",
    "    row = {\n",
    "        \"#HL\": g[\"layers\"], \"#Node\": g[\"nodes\"], \"Activation\": g[\"activation\"],\n",
    "        \"Dropout\": f\"{int((1-g['keep'])*100)}%\", \"Batch\": g[\"batch\"],\n",
    "        \"AUC_Train\": auc_tr, \"AUC_Test1\": auc_t1, \"AUC_Test2\": auc_t2,\n",
    "        \"AUC_Mean\": auc_mu, \"AUC_Std\": auc_sd, \"score\": score\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best = {\"grid\": g, \"metrics\": {\"AUC_Train\": auc_tr, \"AUC_Test1\": auc_t1, \"AUC_Test2\": auc_t2}}\n",
    "\n",
    "grid_df = pd.DataFrame(rows)\n",
    "grid_df.to_csv(OUT / \"nn_grid_results.csv\", index=False)\n",
    "(Path(OUT / \"nn_best_params.json\")).write_text(json.dumps(best, indent=2))\n",
    "print(\"Saved -> outputs/nn_grid_results.csv\")\n",
    "print(\"Best:\", best)\n",
    "\n",
    "# ---------- Refit best NN on Train+Test1, evaluate on Test2, and save ----------\n",
    "g = best[\"grid\"]\n",
    "tf.keras.backend.clear_session()\n",
    "final = make_model(g[\"layers\"], g[\"nodes\"], g[\"activation\"], g[\"keep\"])\n",
    "final.fit(\n",
    "    np.vstack([X_tr_s, X_t1_s]),\n",
    "    np.concatenate([y_tr, y_t1]),\n",
    "    epochs=20, batch_size=g[\"batch\"], verbose=0\n",
    ")\n",
    "\n",
    "p_fit  = final.predict(np.vstack([X_tr_s, X_t1_s]), verbose=0).ravel()\n",
    "p_hold = final.predict(X_t2_s, verbose=0).ravel()\n",
    "print(\"Final NN AUC (fit):   \", roc_auc_score(np.concatenate([y_tr, y_t1]), p_fit))\n",
    "print(\"Final NN AUC (holdout):\", roc_auc_score(y_t2, p_hold))\n",
    "\n",
    "final.save(OUT / \"nn_final.keras\")\n",
    "pd.DataFrame({\"customer_ID\": c_t2, \"y_true\": y_t2, \"score\": p_hold}).to_csv(\n",
    "    OUT / \"nn_scores_test2.csv\", index=False\n",
    ")\n",
    "print(\"Saved -> outputs/nn_final.keras, outputs/nn_scores_test2.csv, outputs/nn_best_params.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fae6f1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB HOLDOUT AUC: 0.945489\n",
      "NN HOLDOUT AUC: 0.942123\n",
      "\n",
      "Winner: XGB → saved to outputs/winner_model.txt\n"
     ]
    }
   ],
   "source": [
    "# Compare models on holdout and record the winner\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "OUT = Path(\"outputs\")\n",
    "xgb_scores = OUT / \"xgb_scores_test2.csv\"\n",
    "nn_scores  = OUT / \"nn_scores_test2.csv\"\n",
    "\n",
    "rows = []\n",
    "if xgb_scores.exists():\n",
    "    df = pd.read_csv(xgb_scores)\n",
    "    rows.append((\"XGB\", roc_auc_score(df[\"y_true\"], df[\"score\"])))\n",
    "if nn_scores.exists():\n",
    "    df = pd.read_csv(nn_scores)\n",
    "    rows.append((\"NN\", roc_auc_score(df[\"y_true\"], df[\"score\"])))\n",
    "\n",
    "if not rows:\n",
    "    raise FileNotFoundError(\"No holdout score files found. Run the XGB/NN steps first.\")\n",
    "\n",
    "for name, auc in rows:\n",
    "    print(f\"{name} HOLDOUT AUC: {auc:.6f}\")\n",
    "\n",
    "winner = max(rows, key=lambda t: t[1])[0]\n",
    "(OUT / \"winner_model.txt\").write_text(winner, encoding=\"utf-8\")\n",
    "print(\"\\nWinner:\", winner, \"→ saved to outputs/winner_model.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f4f13ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using winner: XGB\n",
      "Chosen on TRAIN:\n",
      "  Conservative: {'thr': 0.4, 'def_rate': 0.049258133912927764, 'accepted': 45089.0, 'rev12m': 655.527446846479}\n",
      "  Aggressive : {'thr': 0.5, 'def_rate': 0.06948099799978945, 'accepted': 47495.0, 'rev12m': 739.8265890743073}\n",
      "\n",
      "Conservative @ 0.400\n",
      "  Test1: {'def_rate': 0.04909560723514212, 'accepted': 9675, 'rev12m': 139.78147607681785}\n",
      "  Test2: {'def_rate': 0.06036799669216456, 'accepted': 9674, 'rev12m': 133.17663442033518}\n",
      "\n",
      "Aggressive @ 0.500\n",
      "  Test1: {'def_rate': 0.070049965709807, 'accepted': 10207, 'rev12m': 158.77606182194177}\n",
      "  Test2: {'def_rate': 0.07843522704934146, 'accepted': 10174, 'rev12m': 152.30767116880452}\n",
      "Saved -> outputs/strategy_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Strategy thresholds for the winner model\n",
    "# - Picks thresholds on TRAIN (≤5% and ≤10% default caps)\n",
    "# - Reports metrics on Test1 and Test2\n",
    "from pathlib import Path\n",
    "import json, numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "OUT = Path(\"outputs\")\n",
    "AGG = OUT / \"dev_sample_agg.csv.gz\"\n",
    "SEL = OUT / \"selected_features.txt\"\n",
    "WIN = OUT / \"winner_model.txt\"\n",
    "assert AGG.exists() and SEL.exists() and WIN.exists()\n",
    "\n",
    "winner = WIN.read_text().strip()\n",
    "print(\"Using winner:\", winner)\n",
    "\n",
    "# ---- common data/splits ----\n",
    "df = pd.read_csv(AGG, dtype={\"customer_ID\":\"string\"})\n",
    "target = \"target\" if \"target\" in df.columns else df.columns[-1]\n",
    "with open(SEL, \"r\", encoding=\"utf-8\") as f:\n",
    "    keep = [ln.strip() for ln in f if ln.strip() and ln.strip() in df.columns]\n",
    "\n",
    "X = df[keep].copy()\n",
    "y = df[target].astype(int).values\n",
    "cust = df[\"customer_ID\"].astype(\"string\").values\n",
    "\n",
    "X_tr, X_tmp, y_tr, y_tmp, c_tr, c_tmp = train_test_split(\n",
    "    X, y, cust, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "X_t1, X_t2, y_t1, y_t2, c_t1, c_t2 = train_test_split(\n",
    "    X_tmp, y_tmp, c_tmp, test_size=0.50, random_state=42, stratify=y_tmp\n",
    ")\n",
    "\n",
    "# pick one spend and one balance proxy (for revenue calc)\n",
    "def pick(prefix):\n",
    "    for suff in [\"_mean6\",\"_mean3\",\"_last\"]:\n",
    "        cols = [c for c in df.columns if c.startswith(prefix) and c.endswith(suff)]\n",
    "        if cols: return cols[0]\n",
    "    return None\n",
    "S_col = pick(\"S_\"); B_col = pick(\"B_\")\n",
    "mini = df.set_index(\"customer_ID\")[[c for c in [S_col,B_col] if c]].astype(\"float32\").fillna(0.0)\n",
    "mini = mini.rename(columns={S_col:\"S6\", B_col:\"B6\"})\n",
    "\n",
    "SPEND_FEE = 0.001   # 0.1% of spend\n",
    "APR       = 0.24    # annual interest on balance\n",
    "\n",
    "def eval_at(thr, y_true, pd_hat, ids):\n",
    "    m = pd.DataFrame({\"y\":y_true, \"pd\":pd_hat, \"id\":ids}).join(mini, on=\"id\").fillna(0.0)\n",
    "    acc = m[m.pd < thr]\n",
    "    if len(acc)==0: \n",
    "        return {\"def_rate\":np.nan, \"accepted\":0, \"rev12m\":0.0}\n",
    "    monthly = acc.S6*SPEND_FEE + acc.B6*(APR/12)\n",
    "    return {\n",
    "        \"def_rate\": float(acc.y.mean()),\n",
    "        \"accepted\": int(len(acc)),\n",
    "        \"rev12m\": float((monthly * (1-acc.y)).sum()*12)\n",
    "    }\n",
    "\n",
    "def choose_on_train(pd_tr, ids_tr, cap):\n",
    "    # sweep fixed grid of thresholds 2% → 50%\n",
    "    ths = np.linspace(0.02, 0.50, 25)\n",
    "    rows=[]\n",
    "    m = pd.DataFrame({\"pd\":pd_tr, \"id\":ids_tr}).join(mini, on=\"id\").fillna(0.0)\n",
    "    # need y on train for default rate\n",
    "    # we kept y_tr in outer scope\n",
    "    m[\"y\"] = y_tr\n",
    "    for t in ths:\n",
    "        acc = m[m.pd < t]\n",
    "        if len(acc)==0: continue\n",
    "        monthly = acc.S6*SPEND_FEE + acc.B6*(APR/12)\n",
    "        rows.append({\"thr\":float(t),\n",
    "                     \"def_rate\": float(acc.y.mean()),\n",
    "                     \"accepted\": int(len(acc)),\n",
    "                     \"rev12m\": float((monthly * (1-acc.y)).sum()*12)})\n",
    "    grid = pd.DataFrame(rows)\n",
    "    ok = grid[grid.def_rate <= cap]\n",
    "    return None if ok.empty else ok.sort_values([\"rev12m\",\"accepted\"], ascending=[False,False]).iloc[0].to_dict()\n",
    "\n",
    "if winner == \"XGB\":\n",
    "    import xgboost as xgb\n",
    "    best = json.loads((OUT / \"xgb_best_params.json\").read_text())\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\", eval_metric=\"auc\", tree_method=\"hist\",\n",
    "        random_state=42, n_jobs=-1, **best\n",
    "    ).fit(pd.concat([X_tr, X_t1]), np.concatenate([y_tr, y_t1]))\n",
    "    p_tr  = model.predict_proba(X_tr)[:,1]\n",
    "    p_t1  = model.predict_proba(X_t1)[:,1]\n",
    "    p_t2  = model.predict_proba(X_t2)[:,1]\n",
    "\n",
    "else:  # winner == \"NN\"\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    # preprocessing per brief: cap/floor 1/99, missing->0, StandardScaler\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    q_lo = X_tr.quantile(0.01); q_hi = X_tr.quantile(0.99)\n",
    "    def clip(df_): return df_.clip(q_lo, q_hi, axis=1)\n",
    "    X_tr_c = clip(X_tr).fillna(0.0); X_t1_c = clip(X_t1).fillna(0.0); X_t2_c = clip(X_t2).fillna(0.0)\n",
    "    sc = StandardScaler().fit(X_tr_c)\n",
    "    X_tr_s = sc.transform(X_tr_c); X_t1_s = sc.transform(X_t1_c); X_t2_s = sc.transform(X_t2_c)\n",
    "    model = keras.models.load_model(OUT / \"nn_final.keras\")\n",
    "    p_tr  = model.predict(X_tr_s, verbose=0).ravel()\n",
    "    p_t1  = model.predict(X_t1_s, verbose=0).ravel()\n",
    "    p_t2  = model.predict(X_t2_s, verbose=0).ravel()\n",
    "\n",
    "# choose thresholds on TRAIN\n",
    "cons = choose_on_train(p_tr, c_tr, cap=0.05)   # ≤5% default\n",
    "aggr = choose_on_train(p_tr, c_tr, cap=0.10)   # ≤10% default\n",
    "print(\"Chosen on TRAIN:\")\n",
    "print(\"  Conservative:\", cons)\n",
    "print(\"  Aggressive :\", aggr)\n",
    "\n",
    "# --- Report both strategies and save correctly ---\n",
    "rows = []\n",
    "\n",
    "def add_rows(name, thr):\n",
    "    if thr is None: \n",
    "        return\n",
    "    r1 = eval_at(thr, y_t1, p_t1, c_t1)\n",
    "    r2 = eval_at(thr, y_t2, p_t2, c_t2)\n",
    "    print(f\"\\n{name} @ {thr:.3f}\")\n",
    "    print(\"  Test1:\", r1)\n",
    "    print(\"  Test2:\", r2)\n",
    "    rows.extend([\n",
    "        {\"Strategy\": name, \"Split\": \"Test1\", **r1},\n",
    "        {\"Strategy\": name, \"Split\": \"Test2\", **r2},\n",
    "    ])\n",
    "\n",
    "add_rows(\"Conservative\", cons[\"thr\"])\n",
    "add_rows(\"Aggressive\",   aggr[\"thr\"])\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(rows).to_csv(OUT / \"strategy_summary.csv\", index=False)\n",
    "print(\"Saved -> outputs/strategy_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d146dcfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
